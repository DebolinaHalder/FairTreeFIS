{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "from keras import backend as K\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.special import expit\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from FairTreeFIS import fis_tree, fis_forest, fis_boosting\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, RandomForestRegressor\n",
    "from FairTreeFIS import util\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import logit, expit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import max_norm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def bias_reg(x,y,pred,protected_attribute,protected_val):\n",
    "    protected = ([(x,l) for (x,l) in zip(x,pred) if\n",
    "        x[protected_attribute] == protected_val])\n",
    "    el = ([(x,l) for (x,l) in zip(x,pred) if\n",
    "        x[protected_attribute] != protected_val])\n",
    "    p = sum(l for (x,l) in protected)\n",
    "    q = sum(l for (x,l) in el)\n",
    "    return abs(p/len(protected) - q/len(el))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "dat = pd.read_csv(\"cc.csv\")\n",
    "dat = dat.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "nrow = dat.shape[0]\n",
    "target_sensitive_attribute = \"racePctWhite\"\n",
    "#sensitive_attribute2 = \"race\"\n",
    "target = \"ViolentCrimesPerPop\"\n",
    "#biased_feature1 = \"PctKids2Par\"\n",
    "#biased_feature2 = \"PctLargHouseFam\"\n",
    "drop_features = [target_sensitive_attribute,target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "column_names = list(dat.columns)\n",
    "column_names.remove(target_sensitive_attribute)\n",
    "#column_names.remove(sensitive_attribute2)\n",
    "column_names.remove(target)\n",
    "#column_names.remove(biased_feature1)\n",
    "#column_names.remove(biased_feature2)\n",
    "ncol = len(column_names)\n",
    "\n",
    "###### Visualization of Surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "seeds = np.arange(10)\n",
    "dp = []\n",
    "eq = []\n",
    "accuracy = []\n",
    "for i in seeds:\n",
    "    keras.utils.set_random_seed(int(i))\n",
    "    train, test = train_test_split(dat, test_size=0.3 ,shuffle=True,random_state = 0)\n",
    "    a_train = train[target_sensitive_attribute].to_numpy()\n",
    "    y_train = train[target].to_numpy()\n",
    "    y_train = np.where(y_train != 1, 0, y_train)\n",
    "    train = train.drop(drop_features, axis = 1)\n",
    "    train = train.to_numpy()\n",
    "\n",
    "    a_test = test[target_sensitive_attribute].to_numpy()\n",
    "    y_test = test[target].to_numpy()\n",
    "    y_test = np.where(y_test != 1, 0, y_test)\n",
    "    test = test.drop(drop_features, axis = 1)\n",
    "    test = test.to_numpy()\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(train)\n",
    "    X_test = min_max_scaler.transform(test)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_shape=(X_train.shape[1],), activation='relu')) # (features,)\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear')) # output node\n",
    "    model.summary() # see what your model looks like\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "    # early stopping callback\n",
    "    es = EarlyStopping(monitor='val_loss',\n",
    "                    mode='min',\n",
    "                    patience=50,\n",
    "                    restore_best_weights = True)\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    callbacks=[es],\n",
    "                    epochs=100,\n",
    "                    batch_size=10,\n",
    "                    verbose=1)\n",
    "    pred = model.predict(X_test)\n",
    "    test_with_prot = np.concatenate((test,a_test.reshape(-1,1)),1)\n",
    "    accuracy.append(mean_squared_error(pred,y_test))\n",
    "    dp.append(abs(bias_reg(test_with_prot,y_test,pred,test.shape[1],0)))\n",
    "    eq.append(abs(util.eqop(test_with_prot,y_test,pred,test.shape[1],0))) \n",
    "    \n",
    "       \n",
    "print(np.mean(dp),np.mean(eq),np.mean(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "##### Visualization of Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "seeds = np.arange(10)\n",
    "dp = []\n",
    "eq = []\n",
    "accuracy = []\n",
    "for i in seeds:\n",
    "    \n",
    "    train, test = train_test_split(dat, test_size=0.3 ,shuffle=True,random_state = 0)\n",
    "    a_train = train[target_sensitive_attribute].to_numpy()\n",
    "    y_train = train[target].to_numpy()\n",
    "    y_train = np.where(y_train != 1, 0, y_train)\n",
    "    train = train.drop(drop_features, axis = 1)\n",
    "    train = train.to_numpy()\n",
    "\n",
    "    a_test = test[target_sensitive_attribute].to_numpy()\n",
    "    y_test = test[target].to_numpy()\n",
    "    y_test = np.where(y_test != 1, 0, y_test)\n",
    "    test = test.drop(drop_features, axis = 1)\n",
    "    test = test.to_numpy()\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=100)\n",
    "    clf.fit(train,y_train)\n",
    "    \n",
    "    pred = clf.predict(test)\n",
    "    test_with_prot = np.concatenate((test,a_test.reshape(-1,1)),1)\n",
    "    accuracy.append(mean_squared_error(pred,y_test))\n",
    "    dp.append(abs(bias_reg(test_with_prot,y_test,pred,test.shape[1],0)))\n",
    "    eq.append(abs(util.eqop(test_with_prot,y_test,pred,test.shape[1],0))) \n",
    "    \n",
    "       \n",
    "print(np.mean(dp),np.mean(eq),np.mean(accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
